{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f47522b-a1e5-4f3b-af26-8f87a6fc3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfquery as pq\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e28e0c-3fde-4d21-ac84-0b75704a47f5",
   "metadata": {},
   "source": [
    "Scrape PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0dbe7b-83b8-4369-b390-9abf4fc19d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePdf(pdfPath):\n",
    "    pdf = pq.PDFQuery(pdfPath)\n",
    "    pdf.load()\n",
    "    pdfData = pd.DataFrame({\n",
    "        \"countryName\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 686.86, 211.513, 697.9\")').text(),\n",
    "        \"EPRETRSectorCode\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"180.26, 643.3, 185.857, 654.34\")').text(),\n",
    "        \"eptrSectorName\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"210.29, 643.3, 471.936, 654.34\")').text().split(\" \", 1)[1],\n",
    "        \"EPRTRAnnexIMainActivityCode\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 614.26, 157.097, 625.3\")').text().split(\" \", 1)[1],\n",
    "        \"FacilityInspireID\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 715.9, 266.172, 726.94\")').text().split(\" \", 1)[1],\n",
    "        \"facilityName\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 730.42, 343.076, 741.46\")').text().split(\" \", 2)[2],\n",
    "        \"City\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 672.34, 221.195, 683.38\")').text(),\n",
    "        \"CITY ID\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 175.7, 312.518, 186.74\")').text(),\n",
    "        \"targetRelease\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 570.67, 154.094, 581.71\")').text(),\n",
    "        \"pollutant\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"306.17, 570.67, 406.325, 581.71\")').text(),\n",
    "        \"DAY\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"174.62, 527.11, 185.857, 538.15\")').text(),\n",
    "        \"MONTH\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"347.47, 527.11, 384.086, 538.15\")').text().split(\" \", 1)[\n",
    "            0],\n",
    "        \"reportingYear\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"461.38, 527.11, 483.897, 538.15\")').text(),\n",
    "        \"CONTINENT\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"437.02, 686.86, 473.96, 697.9\")').text(),\n",
    "        \"max_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 452.11, 185.806, 463.15\")').text().split(\" \", 1)[1],\n",
    "        \"avg_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"316.87, 452.11, 483.846, 463.15\")').text().split(\" \", 2)[2],\n",
    "        \"min_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"316.87, 452.11, 483.846, 463.15\")').text().split(\" \", 1)[0],\n",
    "        \"max_temp\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"144.02, 388.01, 185.806, 399.05\")').text(),\n",
    "        \"avg_temp\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"442.06, 388.01, 483.846, 399.05\")').text(),\n",
    "        \"min_temp\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"311.23, 388.01, 405.714, 399.05\")').text().split(\" \", 1)[0],\n",
    "        \"DAYS WITH FOG\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"174.62, 323.93, 185.857, 334.97\")').text(),\n",
    "        \"REPORTER NAME\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"356.95, 233.81, 504.706, 244.85\")').text().split(\":\", 1)[1]\n",
    "    }, index=[0])\n",
    "    \n",
    "    pdfData.rename(columns={'DAYS WITH FOG': 'DAY WITH FOGS'}, inplace=True)\n",
    "    pdfData.rename(columns={'eptrSectorName': 'eprtrSectorName'}, inplace=True)\n",
    "    return pdfData\n",
    "\n",
    "\n",
    "def getPdfNames():\n",
    "    pdfsPath = './pdfs/'\n",
    "    files = [f for f in os.listdir(pdfsPath) if os.path.isfile(os.path.join(pdfsPath, f))]\n",
    "    for file in files:\n",
    "        if file.split(\".\")[1] != 'pdf':\n",
    "            files.remove(file)\n",
    "    files = map(lambda file: pdfsPath + file, files)\n",
    "    return files\n",
    "\n",
    "pdfData = pd.DataFrame()\n",
    "files = getPdfNames()\n",
    "for file in files:\n",
    "    pdfData = pd.concat([pdfData, scrapePdf(file)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd94c1-c882-4549-929d-f1a4cf39b7cf",
   "metadata": {},
   "source": [
    "Get JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdae0f6f-3fe6-4901-9d9b-915d47c5db5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first\n",
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second\n",
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third\n",
      "Index(['CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n",
      "       'EPRTRAnnexIMainActivityCode', 'EPRTRAnnexIMainActivityLabel',\n",
      "       'FacilityInspireID', 'MONTH', 'REPORTER NAME', 'avg_temp',\n",
      "       'avg_wind_speed', 'countryName', 'eprtrSectorName', 'facilityName',\n",
      "       'max_temp', 'max_wind_speed', 'min_temp', 'min_wind_speed', 'pollutant',\n",
      "       'reportingYear', 'targetRelease'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def jsonToDataframe(url):\n",
    "    print(url)\n",
    "    resp = requests.get(url=url)\n",
    "    data = resp.json()\n",
    "    df = pd.DataFrame()\n",
    "    for count, row in enumerate(data):\n",
    "        entry = pd.DataFrame(data[count], index=[count])\n",
    "        df = pd.concat([df, entry], axis='rows')\n",
    "    return df\n",
    "\n",
    "\n",
    "urls = ['http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first',\n",
    "        'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second',\n",
    "        'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third']\n",
    "jsonData = pd.DataFrame()\n",
    "for url in urls:\n",
    "    temp = jsonToDataframe(url)\n",
    "    jsonData = pd.concat([jsonData, temp], axis='rows')\n",
    "#c\n",
    "jsonData.drop(columns=['EPRTRSectorCode'], inplace=True)\n",
    "jsonData.drop(columns=[''], inplace=True)\n",
    "print(jsonData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9a2d6-cf49-4e5e-b2e5-826b52822f41",
   "metadata": {},
   "source": [
    "Get Csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd6f573-b6b0-44cb-9a09-e553d92e59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no existing nulls\n"
     ]
    }
   ],
   "source": [
    "def getcode(label, dictionary):\n",
    "    # based on data from here: https://iir.umweltbundesamt.de/2021/general/point_sources/start\n",
    "    if label == 'Chemical installations for the production on an industrial scale of basic organic chemicals: Organometallic compounds':\n",
    "        return '4(a)(vii)'\n",
    "    return dictionary[label]\n",
    "\n",
    "df1 = pd.read_csv(\"./csvs/train1.csv\")\n",
    "df2 = pd.read_csv(\"./csvs/train2.csv\", sep=';')\n",
    "frames = [df1,df2]\n",
    "csvData = pd.concat(frames)\n",
    "\n",
    "names_list = csvData.columns.to_list()\n",
    "\n",
    "aux = 0\n",
    "for element in names_list:\n",
    "    if csvData[element].isnull().values.any():\n",
    "        aux = aux + 1\n",
    "        print(csvData[element].isnull().values.any())\n",
    "if aux > 0:\n",
    "    print('existing nulls')\n",
    "else:\n",
    "    print('no existing nulls')\n",
    "csvData['EPRTRAnnexIMainActivityCode'] = csvData.apply(lambda row: getcode(row['EPRTRAnnexIMainActivityLabel'], dict(zip(jsonData['EPRTRAnnexIMainActivityLabel'], jsonData['EPRTRAnnexIMainActivityCode']))), axis=1)\n",
    "csvData.drop(columns=['EPRTRAnnexIMainActivityLabel'], inplace=True)\n",
    "jsonData.drop(columns=['EPRTRAnnexIMainActivityLabel'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65aabe9-10c4-4818-94ff-307adde61acb",
   "metadata": {},
   "source": [
    "Unify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a2a968-83dd-44e7-95f0-bbd45b0fea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([jsonData, csvData, pdfData], axis='rows')\n",
    "\n",
    "\n",
    "data.drop(columns=['FacilityInspireID'], inplace=True)\n",
    "data.drop(columns=['facilityName'], inplace=True)\n",
    "data.drop(columns=['targetRelease'], inplace=True)\n",
    "data.drop(columns=['CONTINENT'], inplace=True)\n",
    "data.drop(columns=['REPORTER NAME'], inplace=True)\n",
    "data.drop(columns=['CITY ID'], inplace=True)\n",
    "data.drop(columns=['EPRETRSectorCode'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5c0a-b018-4ac5-bca9-4dedf8e18cbc",
   "metadata": {},
   "source": [
    "We swap min and max values for wind and temperature when min values are greater than max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa3a3d7-6989-4f1c-b8b9-55824764cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['min_wind_speed'] > data['max_wind_speed'], ['min_wind_speed','max_wind_speed']] = data.loc[data['min_wind_speed'] > data['max_wind_speed'], ['max_wind_speed','min_wind_speed']].values\n",
    "data.loc[data['min_temp'] > data['max_temp'], ['min_temp','max_temp']] = data.loc[data['min_temp'] > data['max_temp'], ['max_temp','min_temp']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89332a6d-b0b4-495c-b198-9e270b16a71b",
   "metadata": {},
   "source": [
    "Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ab982-e5bc-41de-95d4-3c64e4822acb",
   "metadata": {},
   "source": [
    "Replace max, min and average temperature and winds for pdf values because they don't have sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab6414c-f09a-4a89-9e9f-dd46f20a74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = data.head(-82)\n",
    "uk = head.loc[head['countryName'] == 'United Kingdom']\n",
    "uk_max_wind = uk['max_wind_speed'].astype(float).mean()\n",
    "uk_min_wind = uk['min_wind_speed'].astype(float).mean()\n",
    "uk_avg_wind = uk['avg_wind_speed'].astype(float).mean()\n",
    "uk_max_temp = uk['max_temp'].astype(float).mean()\n",
    "uk_min_temp = uk['min_temp'].astype(float).mean()\n",
    "uk_avg_temp = uk['avg_temp'].astype(float).mean()\n",
    "tail = data.tail(82)\n",
    "tail = tail.assign(max_wind_speed=uk_max_wind)\n",
    "tail = tail.assign(min_wind_speed=uk_min_wind)\n",
    "tail = tail.assign(avg_wind_speed=uk_avg_wind)\n",
    "tail = tail.assign(max_temp=uk_max_temp)\n",
    "tail = tail.assign(min_temp=uk_min_temp)\n",
    "tail = tail.assign(avg_temp=uk_avg_temp)\n",
    "\n",
    "data = pd.concat([head, tail], axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118346c2-23e9-4f02-bc30-8e6b6218c21c",
   "metadata": {},
   "source": [
    "Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44a4113e-cb3b-4119-a147-38eff4401013",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_general = LabelEncoder()\n",
    "le_pollutant = LabelEncoder()\n",
    "data['pollutant'] = le_pollutant.fit_transform(data['pollutant'])\n",
    "data['countryName'] = le_general.fit_transform(data['countryName'])\n",
    "data['eprtrSectorName'] = le_general.fit_transform(data['eprtrSectorName'])\n",
    "data['City'] = le_general.fit_transform(data['City'])\n",
    "data['EPRTRAnnexIMainActivityCode'] = le_general.fit_transform(data['EPRTRAnnexIMainActivityCode'])\n",
    "features = data.columns.tolist()\n",
    "features.remove('pollutant')\n",
    "X = data[features]\n",
    "y = data['pollutant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fbde1-a33b-4f18-8ca7-ad69e7d659a9",
   "metadata": {},
   "source": [
    "Creation of test and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5e07df2-1279-4649-9705-680e5b72c123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdcdef-fe9e-40af-9484-a0c691218698",
   "metadata": {},
   "source": [
    "KNN Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5de5fa17-1f69-43ff-b668-aee72479095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion's matrix: [[2388  414 1825]\n",
      " [ 505 2556  329]\n",
      " [2020  485 2620]]\n",
      "Accuracy score: 0.5755592756049308\n",
      "Precission score: 0.5755592756049308\n",
      "Recall score: 0.5755592756049308\n",
      "F1 score: 0.5755592756049308\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confussion's matrix: \\n{}\".format(conf_mat))\n",
    "print(\"Accuracy score: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precission score: {}\".format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"Recall score: {}\".format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "print(\"F1 score: {}\".format(metrics.f1_score(y_test, y_pred, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a77983-cb3e-478b-b6fc-52b23dcd841c",
   "metadata": {},
   "source": [
    "Gaussian Naïve Bayes training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb7e33d-a3c2-4521-8a43-58140d383a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion's matrix: \n",
      "[[ 656  904 3067]\n",
      " [  83 2498  809]\n",
      " [ 628 1017 3480]]\n",
      "Accuracy score: 0.5047937908994065\n",
      "Precission score: 0.5047937908994065\n",
      "Recall score: 0.5047937908994065\n",
      "F1 score: 0.5047937908994065\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confussion's matrix: \\n{}\".format(conf_mat))\n",
    "print(\"Accuracy score: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precission score: {}\".format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"Recall score: {}\".format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "print(\"F1 score: {}\".format(metrics.f1_score(y_test, y_pred, average='micro')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65db63-44ef-46b2-b49c-dd6ae03fda50",
   "metadata": {},
   "source": [
    "Random Forest training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e1bbfef-23c0-4b22-af3f-44fb10385e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion's matrix: \n",
      "[[2643   85 1899]\n",
      " [ 189 2904  297]\n",
      " [1517  115 3493]]\n",
      "Accuracy score: 0.6878709481053112\n",
      "Precission score: 0.6878709481053112\n",
      "Recall score: 0.6878709481053112\n",
      "F1 score: 0.6878709481053112\n",
      "Features weight: EPRTRAnnexIMainActivityCode    0.221931\n",
      "eprtrSectorName                0.107912\n",
      "min_wind_speed                 0.068798\n",
      "max_wind_speed                 0.068713\n",
      "City                           0.068150\n",
      "avg_wind_speed                 0.068113\n",
      "min_temp                       0.065433\n",
      "max_temp                       0.065282\n",
      "avg_temp                       0.064712\n",
      "DAY                            0.052260\n",
      "countryName                    0.044333\n",
      "reportingYear                  0.040168\n",
      "MONTH                          0.038129\n",
      "DAY WITH FOGS                  0.026066\n",
      "Falses positives: 4102\n",
      "Falses negatives: 4102\n",
      "Accuracy: 0.694 (0.005)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confussion's matrix: \\n{}\".format(conf_mat))\n",
    "print(\"Accuracy score: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precission score: {}\".format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"Recall score: {}\".format(metrics.recall_score(y_test, y_pred, average='micro')))\n",
    "print(\"F1 score: {}\".format(metrics.f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(\"Features weight: {}\".format(feature_imp.to_string()))\n",
    "\n",
    "FP_0 = conf_mat[1][0] + conf_mat[2][0]\n",
    "FN_0 = conf_mat[0][1] + conf_mat[0][2]\n",
    "FP_1 = conf_mat[0][1] + conf_mat[2][1]\n",
    "FN_1 = conf_mat[1][0] + conf_mat[1][2]\n",
    "FP_2 = conf_mat[0][2] + conf_mat[1][2]\n",
    "FN_2 = conf_mat[2][0] + conf_mat[2][1]\n",
    "\n",
    "FP = FP_0 + FP_1 + FP_2\n",
    "FN = FN_0 + FN_1 + FN_2\n",
    "print(\"Falses positives: {}\".format(FP))\n",
    "print(\"Falses negatives: {}\".format(FN))\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(clf, data.drop('pollutant', axis=1), data['pollutant'], scoring='f1_micro', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82036e1d-1ae5-4faf-b89a-0b75c187a0c0",
   "metadata": {},
   "source": [
    "Let's talk about metrics: We get a reasonable better F1 score compared to others. Important to mark that different scores are equal because we have the same number of false positives and false negatives. We check the weight from the different features: activity code and sector name are the most valuable. We do a cross validation to obtain a more robust result from our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec74a55-4965-469d-945f-12f55c348547",
   "metadata": {},
   "source": [
    "Predictions output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "036f1f82-2ed3-4b32-9f72-eff9833f02cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  DAY  DAY WITH FOGS EPRTRAnnexIMainActivityCode  MONTH  \\\n",
      "0  Rydułtowy   16              1                        3(a)      8   \n",
      "1   Diekirch   22              0                        5(d)     11   \n",
      "2  Eemshaven   19              2                        1(c)      9   \n",
      "3        BRO   17              2                        5(d)      7   \n",
      "4    SETÚBAL   23              2                        1(c)      6   \n",
      "\n",
      "    avg_temp  avg_wind_speed  countryName                  eprtrSectorName  \\\n",
      "0  11.381181       14.855940       Poland                 Mineral industry   \n",
      "1   8.840137       17.623877   Luxembourg  Waste and wastewater management   \n",
      "2   8.403322       15.541979  Netherlands                    Energy sector   \n",
      "3   7.571596       17.458113       Sweden  Waste and wastewater management   \n",
      "4  11.548033       20.532473     Portugal                    Energy sector   \n",
      "\n",
      "    max_temp  max_wind_speed   min_temp  min_wind_speed  reportingYear  \n",
      "0  10.278561       14.080054  13.480752       18.474836           2017  \n",
      "1   6.625910       16.052425  13.422924       22.622900           2008  \n",
      "2   5.669436       13.647318  11.276388       17.818521           2014  \n",
      "3   6.160560       16.336762   9.443572       19.961777           2011  \n",
      "4  10.964012       21.516602  12.624114       21.617137           2010  \n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "test = pd.read_csv('test_x.csv')\n",
    "#test.rename(columns={'EPRTRSectorCode': 'eprtrSectorName'}, inplace=True)\n",
    "test_index = test['test_index']\n",
    "for col in test.columns:\n",
    "    if col not in data.columns:\n",
    "        test.drop(columns=[col], inplace=True)\n",
    "        #print('Dropped ' + str(col))\n",
    "test = test[features]\n",
    "#test.rename(columns={'eprtrSectorName': 'removed'}, inplace=True)\n",
    "print(test.head())\n",
    "test['countryName'] = le_general.fit_transform(test['countryName'])\n",
    "test['eprtrSectorName'] = le_general.fit_transform(test['eprtrSectorName'])\n",
    "test['City'] = le_general.fit_transform(test['City'])\n",
    "test['EPRTRAnnexIMainActivityCode'] = le_general.fit_transform(test['EPRTRAnnexIMainActivityCode'])\n",
    "\n",
    "predictions = clf.predict(test)\n",
    "predictions = le_pollutant.inverse_transform(predictions)\n",
    "final_answer = pd.DataFrame()\n",
    "final_answer['test_index'] = test_index\n",
    "final_answer['prediction'] = pd.Series(predictions)\n",
    "\n",
    "def getPollutantCode(row):\n",
    "    match row['prediction']:\n",
    "        case 'Nitrogen oxides (NOX)':\n",
    "            pollutant = '0'\n",
    "        case 'Carbon dioxide (CO2)':\n",
    "            pollutant = '1'\n",
    "        case 'Methane (CH4)':\n",
    "            pollutant = '2'\n",
    "        case _:\n",
    "            pollutant = '-1'\n",
    "    return pollutant\n",
    "\n",
    "\n",
    "final_answer['pollutant'] = final_answer.apply(lambda row: getPollutantCode(row), axis=1)\n",
    "final_answer.to_csv('predictions.csv', index=False)\n",
    "final_answer.to_json('predictions.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
