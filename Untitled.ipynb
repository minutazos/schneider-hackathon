{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f47522b-a1e5-4f3b-af26-8f87a6fc3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfquery as pq\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e28e0c-3fde-4d21-ac84-0b75704a47f5",
   "metadata": {},
   "source": [
    "Scrape PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0dbe7b-83b8-4369-b390-9abf4fc19d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePdf(pdfPath):\n",
    "    pdf = pq.PDFQuery(pdfPath)\n",
    "    pdf.load()\n",
    "    pdfData = pd.DataFrame({\n",
    "        \"countryName\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 686.86, 211.513, 697.9\")').text(),\n",
    "        \"EPRETRSectorCode\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"180.26, 643.3, 185.857, 654.34\")').text(),\n",
    "        \"eptrSectorName\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"210.29, 643.3, 471.936, 654.34\")').text().split(\" \", 1)[1],\n",
    "        \"EPRTRAnnexIMainActivityCode\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 614.26, 157.097, 625.3\")').text().split(\" \", 1)[1],\n",
    "        \"FacilityInspireID\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 715.9, 266.172, 726.94\")').text().split(\" \", 1)[1],\n",
    "        \"facilityName\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 730.42, 343.076, 741.46\")').text().split(\" \", 2)[2],\n",
    "        \"City\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 672.34, 221.195, 683.38\")').text(),\n",
    "        \"CITY ID\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 175.7, 312.518, 186.74\")').text(),\n",
    "        \"targetRelease\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"138.98, 570.67, 154.094, 581.71\")').text(),\n",
    "        \"pollutant\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"306.17, 570.67, 406.325, 581.71\")').text(),\n",
    "        \"DAY\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"174.62, 527.11, 185.857, 538.15\")').text(),\n",
    "        \"MONTH\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"347.47, 527.11, 384.086, 538.15\")').text().split(\" \", 1)[\n",
    "            0],\n",
    "        \"reportingYear\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"461.38, 527.11, 483.897, 538.15\")').text(),\n",
    "        \"CONTINENT\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"437.02, 686.86, 473.96, 697.9\")').text(),\n",
    "        \"max_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"52.8, 452.11, 185.806, 463.15\")').text().split(\" \", 1)[1],\n",
    "        \"avg_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"316.87, 452.11, 483.846, 463.15\")').text().split(\" \", 2)[2],\n",
    "        \"min_wind_speed\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"316.87, 452.11, 483.846, 463.15\")').text().split(\" \", 1)[0],\n",
    "        \"max_temp\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"144.02, 388.01, 185.806, 399.05\")').text(),\n",
    "        \"avg_temp\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"442.06, 388.01, 483.846, 399.05\")').text(),\n",
    "        \"min_temp\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"311.23, 388.01, 405.714, 399.05\")').text().split(\" \", 1)[0],\n",
    "        \"DAYS WITH FOG\": pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"174.62, 323.93, 185.857, 334.97\")').text(),\n",
    "        \"REPORTER NAME\":\n",
    "            pdf.pq('LTTextLineHorizontal:overlaps_bbox(\"356.95, 233.81, 504.706, 244.85\")').text().split(\":\", 1)[1]\n",
    "    }, index=[0])\n",
    "    \n",
    "    pdfData.rename(columns={'DAYS WITH FOG': 'DAY WITH FOGS'}, inplace=True)\n",
    "    pdfData.rename(columns={'eptrSectorName': 'eprtrSectorName'}, inplace=True)\n",
    "    return pdfData\n",
    "\n",
    "\n",
    "def getPdfNames():\n",
    "    pdfsPath = './pdfs/'\n",
    "    files = [f for f in os.listdir(pdfsPath) if os.path.isfile(os.path.join(pdfsPath, f))]\n",
    "    for file in files:\n",
    "        if file.split(\".\")[1] != 'pdf':\n",
    "            files.remove(file)\n",
    "    files = map(lambda file: pdfsPath + file, files)\n",
    "    return files\n",
    "\n",
    "pdfData = pd.DataFrame()\n",
    "files = getPdfNames()\n",
    "for file in files:\n",
    "    pdfData = pd.concat([pdfData, scrapePdf(file)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd94c1-c882-4549-929d-f1a4cf39b7cf",
   "metadata": {},
   "source": [
    "Get JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdae0f6f-3fe6-4901-9d9b-915d47c5db5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first\n",
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second\n",
      "http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third\n"
     ]
    }
   ],
   "source": [
    "def jsonToDataframe(url):\n",
    "    print(url)\n",
    "    resp = requests.get(url=url)\n",
    "    data = resp.json()\n",
    "    df = pd.DataFrame()\n",
    "    for count, row in enumerate(data):\n",
    "        entry = pd.DataFrame(data[count], index=[count])\n",
    "        df = pd.concat([df, entry], axis='rows')\n",
    "    return df\n",
    "\n",
    "\n",
    "urls = ['http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first',\n",
    "        'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second',\n",
    "        'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third']\n",
    "jsonData = pd.DataFrame()\n",
    "for url in urls:\n",
    "    temp = jsonToDataframe(url)\n",
    "    jsonData = pd.concat([jsonData, temp], axis='rows')\n",
    "#jsonData.drop(columns=['EPRTRAnnexIMainActivityLabel'], inplace=True)\n",
    "jsonData.drop(columns=['EPRETRSectorCode'], inplace=True)\n",
    "jsonData.drop(columns=[''], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9a2d6-cf49-4e5e-b2e5-826b52822f41",
   "metadata": {},
   "source": [
    "Get Csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd6f573-b6b0-44cb-9a09-e553d92e59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no existing nulls\n"
     ]
    }
   ],
   "source": [
    "def getcode(label, dictionary):\n",
    "    # based on data from here: https://iir.umweltbundesamt.de/2021/general/point_sources/start\n",
    "    if label == 'Chemical installations for the production on an industrial scale of basic organic chemicals: Organometallic compounds':\n",
    "        return '4(a)(vii)'\n",
    "    return dictionary[label]\n",
    "\n",
    "df1 = pd.read_csv(\"./csvs/train1.csv\")\n",
    "df2 = pd.read_csv(\"./csvs/train2.csv\", sep=';')\n",
    "frames = [df1,df2]\n",
    "csvData = pd.concat(frames)\n",
    "\n",
    "names_list = csvData.columns.to_list()\n",
    "\n",
    "aux = 0\n",
    "for element in names_list:\n",
    "    if csvData[element].isnull().values.any():\n",
    "        aux = aux + 1\n",
    "        print(csvData[element].isnull().values.any())\n",
    "if aux > 0:\n",
    "    print('existing nulls')\n",
    "else:\n",
    "    print('no existing nulls')\n",
    "csvData['EPRTRAnnexIMainActivityCode'] = csvData.apply(lambda row: getcode(row['EPRTRAnnexIMainActivityLabel'], dict(zip(jsonData['EPRTRAnnexIMainActivityLabel'], jsonData['EPRTRAnnexIMainActivityCode']))), axis=1)\n",
    "csvData.drop(columns=['EPRTRAnnexIMainActivityLabel'], inplace=True)\n",
    "jsonData.drop(columns=['EPRTRAnnexIMainActivityLabel'], inplace=True)\n",
    "#jsonData.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65aabe9-10c4-4818-94ff-307adde61acb",
   "metadata": {},
   "source": [
    "Unify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a2a968-83dd-44e7-95f0-bbd45b0fea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')#pd.concat([jsonData, csvData, pdfData], axis='rows')\n",
    "\n",
    "\"\"\"\n",
    "data.drop(columns=['FacilityInspireID'], inplace=True)\n",
    "data.drop(columns=['facilityName'], inplace=True)\n",
    "data.drop(columns=['targetRelease'], inplace=True)\n",
    "data.drop(columns=['CONTINENT'], inplace=True)\n",
    "data.drop(columns=['REPORTER NAME'], inplace=True)\n",
    "data.drop(columns=['CITY ID'], inplace=True)\n",
    "data.drop(columns=['EPRETRSectorCode'], inplace=True)\"\"\"\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5c0a-b018-4ac5-bca9-4dedf8e18cbc",
   "metadata": {},
   "source": [
    "We swap min and max values for wind and temperature when min values are greater than max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aa3a3d7-6989-4f1c-b8b9-55824764cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['min_wind_speed'] > data['max_wind_speed'], ['min_wind_speed','max_wind_speed']] = data.loc[data['min_wind_speed'] > data['max_wind_speed'], ['max_wind_speed','min_wind_speed']].values\n",
    "data.loc[data['min_temp'] > data['max_temp'], ['min_temp','max_temp']] = data.loc[data['min_temp'] > data['max_temp'], ['max_temp','min_temp']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89332a6d-b0b4-495c-b198-9e270b16a71b",
   "metadata": {},
   "source": [
    "Transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ab982-e5bc-41de-95d4-3c64e4822acb",
   "metadata": {},
   "source": [
    "Replace max, min and average temperature and winds for pdf values because they don't have sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ab6414c-f09a-4a89-9e9f-dd46f20a74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = data.head(-82)\n",
    "uk = head.loc[head['countryName'] == 'United Kingdom']\n",
    "uk_max_wind = uk['max_wind_speed'].astype(float).mean()\n",
    "uk_min_wind = uk['min_wind_speed'].astype(float).mean()\n",
    "uk_avg_wind = uk['avg_wind_speed'].astype(float).mean()\n",
    "uk_max_temp = uk['max_temp'].astype(float).mean()\n",
    "uk_min_temp = uk['min_temp'].astype(float).mean()\n",
    "uk_avg_temp = uk['avg_temp'].astype(float).mean()\n",
    "tail = data.tail(82)\n",
    "tail = tail.assign(max_wind_speed=uk_max_wind)\n",
    "tail = tail.assign(min_wind_speed=uk_min_wind)\n",
    "tail = tail.assign(avg_wind_speed=uk_avg_wind)\n",
    "tail = tail.assign(max_temp=uk_max_temp)\n",
    "tail = tail.assign(min_temp=uk_min_temp)\n",
    "tail = tail.assign(avg_temp=uk_avg_temp)\n",
    "\n",
    "data = pd.concat([head, tail], axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67f18bbe-f87e-4098-a3ad-efbcb2ab35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola caracola\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('dataset.csv')\n",
    "print(\"hola caracola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ad84a6-1d95-4095-bbf7-709658c9556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118346c2-23e9-4f02-bc30-8e6b6218c21c",
   "metadata": {},
   "source": [
    "Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44a4113e-cb3b-4119-a147-38eff4401013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['City', 'DAY', 'DAY WITH FOGS', 'EPRTRAnnexIMainActivityCode', 'MONTH', 'avg_temp', 'avg_wind_speed', 'countryName', 'eprtrSectorName', 'max_temp', 'max_wind_speed', 'min_temp', 'min_wind_speed', 'reportingYear']\n"
     ]
    }
   ],
   "source": [
    "le_general = LabelEncoder()\n",
    "le_pollutant = LabelEncoder()\n",
    "data.drop(columns=data.columns[0], inplace=True)\n",
    "data['pollutant'] = le_pollutant.fit_transform(data['pollutant'])\n",
    "data['countryName'] = le_general.fit_transform(data['countryName'])\n",
    "data['eprtrSectorName'] = le_general.fit_transform(data['eprtrSectorName'])\n",
    "data['City'] = le_general.fit_transform(data['City'])\n",
    "data['EPRTRAnnexIMainActivityCode'] = le_general.fit_transform(data['EPRTRAnnexIMainActivityCode'])\n",
    "features = data.columns.tolist()\n",
    "features.remove('pollutant')\n",
    "X = data[features]\n",
    "y = data['pollutant']\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fbde1-a33b-4f18-8ca7-ad69e7d659a9",
   "metadata": {},
   "source": [
    "Creation of test and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5e07df2-1279-4649-9705-680e5b72c123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdcdef-fe9e-40af-9484-a0c691218698",
   "metadata": {},
   "source": [
    "KNN Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5de5fa17-1f69-43ff-b668-aee72479095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2451  419 1748]\n",
      " [ 477 2548  325]\n",
      " [2007  518 2649]]\n",
      "0.5819509968041394\n",
      "0.5819509968041394\n",
      "0.5819509968041394\n",
      "0.5819509968041394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82036e1d-1ae5-4faf-b89a-0b75c187a0c0",
   "metadata": {},
   "source": [
    "Hablamos de las metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbe62ef7-18c8-456c-b0ad-537e4d4eb3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 127  915 3576]\n",
      " [  22 2660  668]\n",
      " [ 165  982 4027]]\n",
      "0.5184903363262822\n",
      "0.5184903363262822\n",
      "0.5184903363262822\n",
      "0.5184903363262822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bltksk/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bb7e33d-a3c2-4521-8a43-58140d383a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 645  977 2996]\n",
      " [  61 2521  768]\n",
      " [ 664 1043 3467]]\n",
      "0.5047176989803683\n",
      "0.5047176989803683\n",
      "0.5047176989803683\n",
      "0.5047176989803683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.f1_score(y_test, y_pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bbfef-23c0-4b22-af3f-44fb10385e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2596   61 1961]\n",
      " [ 180 2913  257]\n",
      " [1572  119 3483]]\n",
      "0.6842185359914777\n",
      "0.6842185359914777\n",
      "0.6842185359914777\n",
      "0.6842185359914777\n",
      "EPRTRAnnexIMainActivityCode    0.217310\n",
      "eprtrSectorName                0.111532\n",
      "City                           0.068943\n",
      "min_wind_speed                 0.068760\n",
      "max_wind_speed                 0.068740\n",
      "avg_wind_speed                 0.067658\n",
      "max_temp                       0.065634\n",
      "min_temp                       0.065375\n",
      "avg_temp                       0.064354\n",
      "DAY                            0.051975\n",
      "countryName                    0.045066\n",
      "reportingYear                  0.041033\n",
      "MONTH                          0.037565\n",
      "DAY WITH FOGS                  0.026054\n",
      "4150\n",
      "4150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "print(metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(feature_imp.to_string())\n",
    "\n",
    "FP_0 = conf_mat[1][0] + conf_mat[2][0]\n",
    "FN_0 = conf_mat[0][1] + conf_mat[0][2]\n",
    "FP_1 = conf_mat[0][1] + conf_mat[2][1]\n",
    "FN_1 = conf_mat[1][0] + conf_mat[1][2]\n",
    "FP_2 = conf_mat[0][2] + conf_mat[1][2]\n",
    "FN_2 = conf_mat[2][0] + conf_mat[2][1]\n",
    "\n",
    "FP = FP_0 + FP_1 + FP_2\n",
    "FN = FN_0 + FN_1 + FN_2\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(clf, data.drop('pollutant', axis=1), data['pollutant'], scoring='f1_micro', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
